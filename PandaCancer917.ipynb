{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlWmfy8s65bN"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28q1CI555p9f"
      },
      "source": [
        "### Connect to Drive and Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "MYfLehyB4TCc",
        "outputId": "ee210202-6677-444f-9134-cd9d5121bf3a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-00836afd-4e12-43c9-aceb-0d0c1f875e74\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-00836afd-4e12-43c9-aceb-0d0c1f875e74\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"mackenziecheng\",\"key\":\"f6a65b977af5878d731672be3d779496\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xaWgHajG4USV"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Kg2r014ZbF",
        "outputId": "cb56e8ac-e447-4c47-ab12-555183b88752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyrubtob7Utg"
      },
      "source": [
        "### Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTeEvG6B7Eqr",
        "outputId": "b357015a-8fc5-44ba-9440-c85ce5cd7591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.12/dist-packages (1.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from openslide-python) (11.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.12/dist-packages (2025.8.28)\n",
            "Requirement already satisfied: zarr in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.12/dist-packages (2025.8.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tifffile) (2.0.2)\n",
            "Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.12/dist-packages (from zarr) (0.8.1.post1)\n",
            "Requirement already satisfied: numcodecs>=0.14 in /usr/local/lib/python3.12/dist-packages (from numcodecs[crc32c]>=0.14->zarr) (0.16.2)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.12/dist-packages (from zarr) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9 in /usr/local/lib/python3.12/dist-packages (from zarr) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr) (6.0.2)\n",
            "Requirement already satisfied: crc32c>=2.7 in /usr/local/lib/python3.12/dist-packages (from numcodecs[crc32c]>=0.14->zarr) (2.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# # Core WSI handling\n",
        "!pip install openslide-python\n",
        "\n",
        "# # Image processing\n",
        "!pip install opencv-python Pillow\n",
        "\n",
        "!pip install tifffile zarr imagecodecs opencv-python pillow pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XvnHQjwE7iBF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "from glob import glob\n",
        "\n",
        "import tifffile as tiff, zarr\n",
        "import numpy as np\n",
        "import cv2, pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch, torchvision as tv\n",
        "import h5py\n",
        "\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QqOQ8kaG4oB"
      },
      "source": [
        "## Edge Detection - Contour function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TryZzyAXBkLW"
      },
      "outputs": [],
      "source": [
        "def _to_uint8(img):\n",
        "    if img.dtype == np.uint8: return img\n",
        "    x = img.astype(np.float32); mn, mx = float(x.min()), float(x.max())\n",
        "    if mx <= mn: return np.zeros_like(x, dtype=np.uint8)\n",
        "    return ((x - mn) / (mx - mn) * 255.0).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 通过饱和度分离组织和背景（饱和度高和白色）\n",
        "# 去掉噪点，让组织区域更连贯\n",
        "# 找到轮廓线 cv2.findContours\n",
        "def build_contour_mask_1024(\n",
        "    lowres_rgb, # 低分辨率彩色图\n",
        "    mthresh: int = 41,        # 去噪点\n",
        "    sthresh: int = 12,        # 分离前景背景\n",
        "    close: int = 2,           # morphology closing kernel\n",
        "    min_area_fore: int = 12,  # min area (low-res px) 低分辩像素个数\n",
        "    min_area_hole: int = 8,  # min hole area (low-res px)\n",
        "    max_n_holes: int = 8,     # cap holes per region 最多保留孔洞数量\n",
        "):\n",
        "\n",
        "\n",
        "    img = _to_uint8(lowres_rgb)\n",
        "    # 组织区域更有颜色，和白色对比强\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV); sat = hsv[..., 1]\n",
        "    sat = cv2.medianBlur(sat, int(max(1, mthresh) | 1))\n",
        "    _, bin_s = cv2.threshold(sat, int(sthresh), 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 填补小缝隙\n",
        "    if close > 0:\n",
        "        kernel = np.ones((int(close), int(close)), np.uint8)\n",
        "        bin_s = cv2.morphologyEx(bin_s, cv2.MORPH_CLOSE, kernel)\n",
        "    contours, hier = cv2.findContours(bin_s, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    if hier is None or len(contours) == 0:\n",
        "        return (bin_s > 0)\n",
        "    hier = hier[0]  # [Next, Prev, First_Child, Parent]\n",
        "    fore_ids = [i for i,h in enumerate(hier) if h[3] == -1]\n",
        "    kept_fore, holes_per_fore = [], []\n",
        "    for fid in fore_ids:\n",
        "        a = cv2.contourArea(contours[fid])\n",
        "        if a <= 0: continue\n",
        "        # collect children (holes)\n",
        "        holes = []\n",
        "        child = hier[fid][2]\n",
        "        while child != -1:\n",
        "            holes.append(child)\n",
        "            child = hier[child][0]\n",
        "        hole_areas = [cv2.contourArea(contours[h]) for h in holes]\n",
        "        real_a = a - (np.sum(hole_areas) if hole_areas else 0.0)\n",
        "        if real_a >= float(min_area_fore):\n",
        "            kept_fore.append(fid)\n",
        "            holes_kept = [h for h in holes if cv2.contourArea(contours[h]) > float(min_area_hole)]\n",
        "            holes_kept = sorted(holes_kept, key=lambda h: cv2.contourArea(contours[h]), reverse=True)[:max_n_holes]\n",
        "            holes_per_fore.append(holes_kept)\n",
        "    H, W = bin_s.shape\n",
        "    mask = np.zeros((H, W), dtype=np.uint8)\n",
        "    if kept_fore:\n",
        "        cv2.drawContours(mask, [contours[i] for i in kept_fore], -1, 255, thickness=cv2.FILLED)\n",
        "    for holes in holes_per_fore:\n",
        "        if holes:\n",
        "            cv2.drawContours(mask, [contours[i] for i in holes], -1, 0, thickness=cv2.FILLED)\n",
        "    return (mask > 0)\n",
        "\n",
        "\n",
        "# 是否留下patch\n",
        "# 组织是否较多？是否有边缘？\n",
        "def patch_keep(mask_bool, x_m, y_m, w_m, h_m):\n",
        "    H, W = mask_bool.shape[:2]\n",
        "    x2, y2 = min(W, x_m + w_m), min(H, y_m + h_m)\n",
        "    if x_m >= x2 or y_m >= y2: return False, {'cov':0.0,'edge':0.0}\n",
        "    win = mask_bool[y_m:y2, x_m:x2]\n",
        "    if win.size == 0: return False, {'cov':0.0,'edge':0.0}\n",
        "    cov = float(win.mean())\n",
        "    if cov == 0.0:\n",
        "        edge_ratio = 0.0\n",
        "    else:\n",
        "        eroded = cv2.erode(win.astype(np.uint8), np.ones((3,3), np.uint8), 1).astype(bool)\n",
        "        border = win ^ eroded\n",
        "        edge_ratio = float(border.mean())\n",
        "    keep = (cov > 0) or (edge_ratio > 0)\n",
        "    return keep, {'cov': cov, 'edge': edge_ratio}\n",
        "\n",
        "# 打分数\n",
        "# score = 0.6 * 组织覆盖率 + 0.4 * edge\n",
        "def rank_key(stats: dict, alpha: float = 0.6):\n",
        "    return alpha*float(stats.get('cov',0.0)) + (1.0-alpha)*float(stats.get('edge',0.0))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_contour_mask_1024_explain(\n",
        "    lowres_rgb,\n",
        "    mthresh: int = 41,\n",
        "    sthresh: int = 12,\n",
        "    close: int = 2,\n",
        "    min_area_fore: int = 12,\n",
        "    min_area_hole: int = 8,\n",
        "    max_n_holes: int = 8,\n",
        "):\n",
        "    debug = {}  # 存每一步的中间产物 & 决策日志\n",
        "\n",
        "    img = _to_uint8(lowres_rgb)\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    sat = hsv[..., 1]\n",
        "\n",
        "    k_med = int(max(1, mthresh) | 1)\n",
        "    sat_blur = cv2.medianBlur(sat, k_med)\n",
        "    _, bin_s = cv2.threshold(sat_blur, int(sthresh), 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    debug['sat'] = sat\n",
        "    debug['sat_blur'] = sat_blur\n",
        "    debug['bin_s_thresh'] = (bin_s > 0)\n",
        "\n",
        "    if close > 0:\n",
        "        kernel = np.ones((int(close), int(close)), np.uint8)\n",
        "        bin_s = cv2.morphologyEx(bin_s, cv2.MORPH_CLOSE, kernel)\n",
        "    debug['bin_s_after_close'] = (bin_s > 0)\n",
        "\n",
        "    contours, hier = cv2.findContours(bin_s, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    H, W = bin_s.shape\n",
        "    if hier is None or len(contours) == 0:\n",
        "        debug['contours'] = []\n",
        "        return (bin_s > 0), debug\n",
        "\n",
        "    hier = hier[0]  # [Next, Prev, First_Child, Parent]\n",
        "    fore_ids = [i for i, h in enumerate(hier) if h[3] == -1]\n",
        "\n",
        "    kept_fore, holes_per_fore = [], []\n",
        "    decisions = []  # 记录每个外轮廓的面积、洞面积、是否保留、原因\n",
        "    for fid in fore_ids:\n",
        "        a = cv2.contourArea(contours[fid])\n",
        "        if a <= 0:\n",
        "            decisions.append({'fid': fid, 'area': a, 'keep': False, 'reason': 'non_positive_area'})\n",
        "            continue\n",
        "        # 收集洞\n",
        "        holes = []\n",
        "        child = hier[fid][2]\n",
        "        while child != -1:\n",
        "            holes.append(child)\n",
        "            child = hier[child][0]\n",
        "        hole_areas = [cv2.contourArea(contours[h]) for h in holes]\n",
        "        real_a = a - (np.sum(hole_areas) if hole_areas else 0.0)\n",
        "\n",
        "        if real_a >= float(min_area_fore):\n",
        "            kept_fore.append(fid)\n",
        "            holes_kept = [h for h in holes if cv2.contourArea(contours[h]) > float(min_area_hole)]\n",
        "            holes_kept = sorted(holes_kept, key=lambda h: cv2.contourArea(contours[h]), reverse=True)[:max_n_holes]\n",
        "            holes_per_fore.append(holes_kept)\n",
        "            decisions.append({\n",
        "                'fid': fid, 'area': float(a), 'real_area': float(real_a),\n",
        "                'n_holes': len(holes), 'hole_areas_sum': float(np.sum(hole_areas) if hole_areas else 0.0),\n",
        "                'keep': True, 'reason': 'ok_area',\n",
        "            })\n",
        "        else:\n",
        "            decisions.append({\n",
        "                'fid': fid, 'area': float(a), 'real_area': float(real_a),\n",
        "                'n_holes': len(holes), 'hole_areas_sum': float(np.sum(hole_areas) if hole_areas else 0.0),\n",
        "                'keep': False, 'reason': 'real_area_below_min_area_fore',\n",
        "            })\n",
        "\n",
        "    mask = np.zeros((H, W), dtype=np.uint8)\n",
        "    if kept_fore:\n",
        "        cv2.drawContours(mask, [contours[i] for i in kept_fore], -1, 255, thickness=cv2.FILLED)\n",
        "    for holes in holes_per_fore:\n",
        "        if holes:\n",
        "            cv2.drawContours(mask, [contours[i] for i in holes], -1, 0, thickness=cv2.FILLED)\n",
        "\n",
        "    debug['decisions'] = decisions\n",
        "    debug['mask_final'] = (mask > 0)\n",
        "    debug['params'] = dict(\n",
        "        mthresh=mthresh, sthresh=sthresh, close=close,\n",
        "        min_area_fore=min_area_fore, min_area_hole=min_area_hole, max_n_holes=max_n_holes\n",
        "    )\n",
        "    return (mask > 0), debug"
      ],
      "metadata": {
        "id": "wbYZuI9Momzc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contour_mask, dbg = build_contour_mask_1024_explain(lowres_rgb,\n",
        "    mthresh=41, sthresh=12, close=2,\n",
        "    min_area_fore=12, min_area_hole=8, max_n_holes=8\n",
        ")\n",
        "\n",
        "# 事后检查哪些外轮廓被筛掉、为什么\n",
        "from collections import Counter\n",
        "print(Counter([d['reason'] for d in dbg['decisions'] if d.get('keep') is False]))\n",
        "# 例如输出：{'real_area_below_min_area_fore': 37}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jlcuGoQooEs",
        "outputId": "47c70095-45a9-45f9-f5c9-43829ea35e20"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"debug keys:\", dbg.keys())\n",
        "print(\"has_contours_decisions:\", 'decisions' in dbg, type(dbg.get('decisions')))\n",
        "if 'decisions' in dbg:\n",
        "    dec = dbg['decisions']\n",
        "    print(\"num_decisions:\", len(dec))\n",
        "    n_keep  = sum(1 for d in dec if d.get('keep') is True)\n",
        "    n_drop  = sum(1 for d in dec if d.get('keep') is False)\n",
        "    print(\"kept:\", n_keep, \" dropped:\", n_drop)\n",
        "    from collections import Counter\n",
        "    print(\"drop_reasons:\", Counter([d['reason'] for d in dec if d.get('keep') is False]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY4NOdIdo5V3",
        "outputId": "219e54df-feb7-47e3-f93a-0844a4c16aed"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debug keys: dict_keys(['sat', 'sat_blur', 'bin_s_thresh', 'bin_s_after_close', 'decisions', 'mask_final', 'params'])\n",
            "has_contours_decisions: True <class 'list'>\n",
            "num_decisions: 1\n",
            "kept: 1  dropped: 0\n",
            "drop_reasons: Counter()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scale = downs[hi_level] / downs[low_level]\n",
        "stride_low = STRIDE * scale\n",
        "w_m = PATCH * scale\n",
        "print(\"stride_low≈\", stride_low, \" w_m≈\", w_m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8teQd-pypEmd",
        "outputId": "fd469663-58bb-4c3a-a216-1e5dbdc2d6e7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stride_low≈ 512.0  w_m≈ 1024.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys, xs = np.where(miss)\n",
        "print(xs.min(), xs.max(), ys.min(), ys.max(), \" | image W_low,H_low=\", W_low, H_low)\n",
        "# 再看有多少 miss 靠近边缘 3 像素：\n",
        "edge_band = 3\n",
        "near_right = np.sum(xs >= W_low - edge_band)\n",
        "near_bottom = np.sum(ys >= H_low - edge_band)\n",
        "print(\"near_right:\", near_right, \" near_bottom:\", near_bottom)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYz--b3oppiP",
        "outputId": "f083ef75-45bf-4ba3-807a-92c2545f5556"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "277 314 1537 1540  | image W_low,H_low= 1728 1840\n",
            "near_right: 0  near_bottom: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuKcliGy5wQE"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tMtz_p-A4axj"
      },
      "outputs": [],
      "source": [
        "drive_path = '/content/drive/MyDrive/PANDA_OneImage'\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "image_id = '0005f7aaab2800f6170c399693a96917'\n",
        "image_filename = f'train_images/{image_id}.tiff'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ2hyLD94mT_",
        "outputId": "0670c7cd-d07c-49ca-9388-e3530846310a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "0005f7aaab2800f6170c399693a96917.tiff: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c prostate-cancer-grade-assessment -f train.csv -p '{drive_path}'\n",
        "!kaggle competitions download -c prostate-cancer-grade-assessment -f '{image_filename}' -p '{drive_path}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McnWP4JsxYxl",
        "outputId": "545ee24e-ffc8-4392-da16-f9c68d666c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train.csv', '0005f7aaab2800f6170c399693a96917.tiff', 'patches_20x', 'extracted']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(drive_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6PtuKSjpUN0",
        "outputId": "f57abd18-477a-458d-d1e5-010b43e8b216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Exists: True\n",
            "Size (MB): 15.38\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, pathlib\n",
        "drive_path = '/content/drive/MyDrive/PANDA_OneImage'\n",
        "image_id = '0005f7aaab2800f6170c399693a96917'\n",
        "image_filename = f'{image_id}.tiff'\n",
        "tiff_path = os.path.join(drive_path, image_filename)\n",
        "\n",
        "print(\"Exists:\", os.path.exists(tiff_path))\n",
        "print(\"Size (MB):\", round(os.path.getsize(tiff_path)/1024/1024, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYMrpHq7zdxa"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY3rYfKO8p1t"
      },
      "source": [
        "## Import and unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKY4OoOz8Hok"
      },
      "source": [
        "*   Many documents implment with OpenSlide, but this Kaggle one does not work as it's a zip --> tifffile and zarr\n",
        "\n",
        "\n",
        "*   forgetground threshold: reject patches if less than % of pixels are tissues\n",
        "\n",
        "*   min std: reject patches with low variations (blank)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TuofGemusdP1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# with tiff.TiffFile(f'{drive_path}/0005f7aaab2800f6170c399693a96917.tiff') as tf:\n",
        "#   print(len(tf.series[0].levels))   # number of pyramid levels\n",
        "#   for lvl in tf.series[0].levels:\n",
        "#     print(lvl.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yaVREMyN1bnY"
      },
      "outputs": [],
      "source": [
        "ZIP_OR_TIFF_PATH = f'/content/drive/MyDrive/PANDA_OneImage/{image_id}.tiff'\n",
        "\n",
        "# output path\n",
        "EXTRACT_DIR = '/content/drive/MyDrive/PANDA_OneImage/extracted'     # where we unzip and get the real tiff\n",
        "OUT_DIR     = '/content/drive/MyDrive/PANDA_OneImage/patches_20x'   # where we save patches/CSV, all outputs\n",
        "\n",
        "\n",
        "\n",
        "# resolution flag\n",
        "# reso = '20x'\n",
        "reso = '20x'\n",
        "\n",
        "Path(EXTRACT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bsiMhCLq14kF"
      },
      "outputs": [],
      "source": [
        "# unzip the file and return the real tiff\n",
        "def get_real_tiff(path: str):\n",
        "    # if file starts with 'PK', it's a ZIP\n",
        "    with open(path, 'rb') as f:\n",
        "        sig = f.read(2)\n",
        "    if sig == b'PK':\n",
        "        with zipfile.ZipFile(path) as z:\n",
        "            print('Archive contents:', z.namelist())\n",
        "            z.extractall(EXTRACT_DIR)\n",
        "        tiffs = sorted(glob(os.path.join(EXTRACT_DIR, '**', '*.tif*'), recursive=True))\n",
        "        if not tiffs:\n",
        "            raise FileNotFoundError('No .tif/.tiff found after extraction.')\n",
        "        return tiffs[0]\n",
        "    return path\n",
        "\n",
        "\n",
        "# zarr: n-dimensional array, like NumPy, but load what you need when you need\n",
        "# WSIs giant -> zarr\n",
        "# get the actual array of the pixel data\n",
        "def _to_zarr_array(znode):\n",
        "    obj = zarr.open(znode, mode='r')\n",
        "    # if a single array\n",
        "    if isinstance(obj, zarr.Array):\n",
        "        return obj\n",
        "    # if a group with multi arrays\n",
        "    if isinstance(obj, zarr.Group):\n",
        "        keys = list(obj.array_keys())\n",
        "        if not keys:\n",
        "            raise ValueError('Zarr Group has no arrays.')\n",
        "        return obj[keys[0]]\n",
        "    raise TypeError(f'Unexpected zarr node type: {type(obj)}')\n",
        "\n",
        "\n",
        "# open the first image in tiff\n",
        "# collect all levels （pyramid) , 40x --> 20x --> 10x....\n",
        "def open_pyramid_as_zarr(tf: tiff.TiffFile):\n",
        "\n",
        "    s0 = tf.series[0]\n",
        "    arr0 = _to_zarr_array(s0.aszarr())        # level 0 (highest resolution)\n",
        "    levels = [arr0] + [_to_zarr_array(l.aszarr()) for l in s0.levels]\n",
        "    # compute downsample factors related to level 0\n",
        "    # eg: L0 wid = 1000, L1 wid = 500, 1000 / 500 = 2\n",
        "    downs = [1.0] + [arr0.shape[-2] / lvl.shape[-2] for lvl in levels[1:]]\n",
        "    return levels, downs\n",
        "\n",
        "# pick the one closest to my target, 20X here\n",
        "def pick_level_for_target(downs, target_down=1.0):\n",
        "    return int(np.argmin([abs(d - target_down) for d in downs]))\n",
        "\n",
        "# standardize all to RGB unit8 format (H, W, 3)\n",
        "def ensure_hwc(tile: np.ndarray):\n",
        "    t = tile\n",
        "    if t.ndim == 2: # grayscale\n",
        "        t = np.stack([t]*3, axis=-1)\n",
        "    elif t.ndim == 3 and t.shape[0] in (3,4) and t.shape[-1] not in (3,4): # (C, H, W)\n",
        "        t = np.moveaxis(t, 0, -1)  # (C,H,W) -> (H,W,C)\n",
        "    if t.shape[-1] > 3: # RGBA with alpha\n",
        "        t = t[..., :3]            # drop alpha\n",
        "    if t.dtype != np.uint8: # other format\n",
        "        # best-effort clamp/convert (many WSIs are already uint8)\n",
        "        t = np.clip(t, 0, 255).astype(np.uint8)\n",
        "    return t\n",
        "\n",
        "def save_png(arr: np.ndarray, path: Path):\n",
        "    Image.fromarray(arr).save(path, format='PNG', compress_level=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcf5CDNR16Ns",
        "outputId": "9a930f13-c5b9-432c-e62a-05612d903a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive contents: ['0005f7aaab2800f6170c399693a96917.tiff']\n",
            "Using TIFF: /content/drive/MyDrive/PANDA_OneImage/extracted/0005f7aaab2800f6170c399693a96917.tiff\n"
          ]
        }
      ],
      "source": [
        "REAL_TIFF_PATH = get_real_tiff(ZIP_OR_TIFF_PATH)\n",
        "print('Using TIFF:', REAL_TIFF_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xm8h6hrxqB76"
      },
      "outputs": [],
      "source": [
        "with tiff.TiffFile(REAL_TIFF_PATH) as tf:\n",
        "    series = tf.series[0]\n",
        "    low = series.levels[-1].asarray()\n",
        "    img = Image.fromarray(low)\n",
        "\n",
        "img.save(f\"original{image_id}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5xjN856tTWW",
        "outputId": "fe36fadd-0109-4132-bc5f-88589fb702c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "(29440, 27648, 3)\n",
            "(7360, 6912, 3)\n",
            "(1840, 1728, 3)\n"
          ]
        }
      ],
      "source": [
        "import tifffile as tiff\n",
        "with tiff.TiffFile('/content/drive/MyDrive/PANDA_OneImage/extracted/0005f7aaab2800f6170c399693a96917.tiff') as tf:\n",
        "    print(len(tf.series[0].levels))   # number of pyramid levels\n",
        "    for lvl in tf.series[0].levels:\n",
        "        print(lvl.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XnKy-3WtigJD"
      },
      "outputs": [],
      "source": [
        "if reso == '20x':\n",
        "  # base level: 20X\n",
        "  hi_level = 0\n",
        "  PATCH, STRIDE = 1024, 512\n",
        "  TARGET_DOWN = 1.0\n",
        "\n",
        "else:\n",
        "  # 10x level\n",
        "  hi_level = 1\n",
        "  PATCH, STRIDE = 512, 256\n",
        "  TARGET_DOWN = 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEGwdPnkt9Nw",
        "outputId": "09835c75-8284-4790-c39f-231357ccdddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pyramid downsample factors vs level-0: ['1.00×', '1.00×', '0.25×', '1.00×']\n",
            "Chosen level: 0  (downsample 1.00×),  shape≈(1840, 1728, …)\n"
          ]
        }
      ],
      "source": [
        "with tiff.TiffFile(REAL_TIFF_PATH) as tf:\n",
        "    levels, downs = open_pyramid_as_zarr(tf)\n",
        "\n",
        "print('Pyramid downsample factors vs level-0:', [f'{d:.2f}×' for d in downs])\n",
        "\n",
        "L = pick_level_for_target(downs, TARGET_DOWN)\n",
        "arrL = levels[L]\n",
        "\n",
        "# extract H and W\n",
        "H, W = arrL.shape[-3], arrL.shape[-2]\n",
        "print(f'Chosen level: {L}  (downsample {downs[L]:.2f}×),  shape≈({H}, {W}, …)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fbBewaLG83n"
      },
      "source": [
        "# Run Contour part to get the non-black part"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_low_rect_from_hi(x_hi, y_hi, PATCH, downs_hi, downs_low, W_low, H_low, PAD=2):\n",
        "    # 起点用 floor（整除等价），再对称外扩 PAD\n",
        "    x_m = (x_hi * downs_hi) // downs_low - PAD\n",
        "    y_m = (y_hi * downs_hi) // downs_low - PAD\n",
        "    # 宽高用 ceil（整除等价），再 +2*PAD\n",
        "    w_m = ((PATCH * downs_hi) + (downs_low - 1)) // downs_low + 2*PAD\n",
        "    h_m = w_m  # 若你的 PATCH 非正方形，这里分开算\n",
        "\n",
        "    # 边界裁剪\n",
        "    x_m = max(0, int(x_m)); y_m = max(0, int(y_m))\n",
        "    x2  = min(int(W_low), int(x_m + w_m))\n",
        "    y2  = min(int(H_low), int(y_m + h_m))\n",
        "    return x_m, y_m, x2, y2, int(x2 - x_m), int(y2 - y_m)"
      ],
      "metadata": {
        "id": "xlMBW5itrzjw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehxgpwYqg-TJ",
        "outputId": "d9e14cca-7dff-40ed-aa40-4b7b49d1878c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3390319847.py:48: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  Image.fromarray(_to_uint8(tile), 'RGB').save(os.path.join(out_dir, f'p_x{x}_y{y}_s{score:.3f}.png'))\n",
            "/tmp/ipython-input-3390319847.py:79: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  Image.fromarray(_to_uint8(tile), 'RGB').save(\n"
          ]
        }
      ],
      "source": [
        "# choose the lowest reso to build the mask\n",
        "low_level = len(levels) - 1\n",
        "arr_low = levels[low_level]\n",
        "lowres_rgb = np.asarray(arr_low)  # (H_low, W_low, 3) uint8\n",
        "H_low, W_low = lowres_rgb.shape[:2]\n",
        "\n",
        "\n",
        "\n",
        "arr0 = levels[hi_level]\n",
        "H0, W0 = arr0.shape[0], arr0.shape[1]\n",
        "\n",
        "# Map factor: pixels at hi_level → pixels at low_level\n",
        "# If your 'downs' is defined as (down from level 0), then:\n",
        "#   scale_hi_to_low = downs[hi_level] / downs[low_level]\n",
        "# For hi_level=0 this simplifies to:\n",
        "scale_hi_to_low = downs[hi_level] / downs[low_level]\n",
        "\n",
        "# Build the contour mask at the low-res level\n",
        "contour_mask = build_contour_mask_1024(lowres_rgb)\n",
        "\n",
        "\n",
        "out_dir = f'patches_out_{reso}'; os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "kept = []\n",
        "for y in range(0, H0 - PATCH + 1, STRIDE):\n",
        "    for x in range(0, W0 - PATCH + 1, STRIDE):\n",
        "        # Map hi-res patch → low-res mask window\n",
        "        # x_m = int(x * scale_hi_to_low)\n",
        "        # y_m = int(y * scale_hi_to_low)\n",
        "        # w_m = max(1, int(PATCH * scale_hi_to_low))\n",
        "        # h_m = max(1, int(PATCH * scale_hi_to_low))\n",
        "\n",
        "        x_m, y_m, x2, y2, w_m, h_m = compute_low_rect_from_hi(\n",
        "            x, y, PATCH, downs[hi_level], downs[low_level], W_low, H_low, PAD=2\n",
        "        )\n",
        "\n",
        "        keep, stats = patch_keep(contour_mask, x_m, y_m, w_m, h_m)\n",
        "        if not keep:\n",
        "            continue\n",
        "\n",
        "        score = rank_key(stats, alpha=0.6)\n",
        "        kept.append((score, x, y))\n",
        "\n",
        "        # Read hi-res tile directly from zarr and save\n",
        "        tile = np.asarray(arr0[y:y+PATCH, x:x+PATCH, :])\n",
        "        if tile.shape[:2] != (PATCH, PATCH):\n",
        "            continue\n",
        "        Image.fromarray(_to_uint8(tile), 'RGB').save(os.path.join(out_dir, f'p_x{x}_y{y}_s{score:.3f}.png'))\n",
        "\n",
        "# 上面的部分，只考虑循环到了最后一个PATCH的倍数就停止了，但假如图片的h和w不是PATCH的整数倍，那么就会在最右边和最左边留下一条细缝没有被cover\n",
        "\n",
        "# 对齐右边缘，强制放一个窗口贴齐最右边\n",
        "x = W0 - PATCH\n",
        "for y in range(0, H0 - PATCH + 1, STRIDE):\n",
        "    x_m, y_m, x2, y2, w_m, h_m = compute_low_rect_from_hi(\n",
        "        x, y, PATCH, downs[hi_level], downs[low_level], W_low, H_low, PAD=2\n",
        "    )\n",
        "    keep, stats = patch_keep(contour_mask, x_m, y_m, w_m, h_m)\n",
        "    if keep:\n",
        "        score = rank_key(stats, alpha=0.6)\n",
        "        kept.append((score, x, y))\n",
        "        tile = np.asarray(arr0[y:y+PATCH, x:x+PATCH, :])\n",
        "        if tile.shape[:2] == (PATCH, PATCH):\n",
        "            Image.fromarray(_to_uint8(tile), 'RGB').save(\n",
        "                os.path.join(out_dir, f'p_x{x}_y{y}_s{score:.3f}.png')\n",
        "            )\n",
        "\n",
        "# 对齐最下边缘\n",
        "y = H0 - PATCH\n",
        "for x in range(0, W0 - PATCH + 1, STRIDE):\n",
        "    x_m, y_m, x2, y2, w_m, h_m = compute_low_rect_from_hi(\n",
        "        x, y, PATCH, downs[hi_level], downs[low_level], W_low, H_low, PAD=2\n",
        "    )\n",
        "    keep, stats = patch_keep(contour_mask, x_m, y_m, w_m, h_m)\n",
        "    if keep:\n",
        "        score = rank_key(stats, alpha=0.6)\n",
        "        kept.append((score, x, y))\n",
        "        tile = np.asarray(arr0[y:y+PATCH, x:x+PATCH, :])\n",
        "        if tile.shape[:2] == (PATCH, PATCH):\n",
        "            Image.fromarray(_to_uint8(tile), 'RGB').save(\n",
        "                os.path.join(out_dir, f'p_x{x}_y{y}_s{score:.3f}.png')\n",
        "            )\n",
        "\n",
        "# 覆盖右下角那个方块\n",
        "x = W0 - PATCH\n",
        "y = H0 - PATCH\n",
        "x_m, y_m, x2, y2, w_m, h_m = compute_low_rect_from_hi(\n",
        "    x, y, PATCH, downs[hi_level], downs[low_level], W_low, H_low, PAD=2\n",
        ")\n",
        "keep, stats = patch_keep(contour_mask, x_m, y_m, w_m, h_m)\n",
        "if keep:\n",
        "    score = rank_key(stats, alpha=0.6)\n",
        "    kept.append((score, x, y))\n",
        "    tile = np.asarray(arr0[y:y+PATCH, x:x+PATCH, :])\n",
        "    if tile.shape[:2] == (PATCH, PATCH):\n",
        "        Image.fromarray(_to_uint8(tile), 'RGB').save(\n",
        "            os.path.join(out_dir, f'p_x{x}_y{y}_s{score:.3f}.png')\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cover = np.zeros_like(contour_mask, dtype=np.uint8)\n",
        "# for (_, x, y) in kept:\n",
        "#     x_m, y_m, x2, y2, _, _ = compute_low_rect_from_hi(\n",
        "#         x, y, PATCH, downs[hi_level], downs[low_level], W_low, H_low, PAD=2\n",
        "#     )\n",
        "#     cover[y_m:y2, x_m:x2] = 1\n",
        "\n",
        "# miss = (contour_mask.astype(bool) & (cover == 0))\n",
        "# print(\"missed pixels:\", int(miss.sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUgefDannE_j",
        "outputId": "b8e8666a-dab2-4366-ce6b-467379f35caf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missed pixels: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmwRFC1cD-kV",
        "outputId": "dbe63ce4-3b2c-4442-dfeb-99ae482796ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed 20x saved at reconstructed_20x.png\n"
          ]
        }
      ],
      "source": [
        "\n",
        "PATCH_DIR = f\"patches_out_{reso}\"\n",
        "pattern = re.compile(r\"p_x(\\d+)_y(\\d+)_s[\\d.]+\\.png\")\n",
        "\n",
        "patches = []\n",
        "max_x, max_y = 0, 0\n",
        "\n",
        "for fname in os.listdir(PATCH_DIR):\n",
        "    match = pattern.match(fname)\n",
        "    if not match:\n",
        "        continue\n",
        "    x, y = int(match.group(1)), int(match.group(2))\n",
        "    img = Image.open(os.path.join(PATCH_DIR, fname))\n",
        "    w, h = img.size\n",
        "    patches.append((x, y, img))\n",
        "\n",
        "    max_x = max(max_x, x + w)\n",
        "    max_y = max(max_y, y + h)\n",
        "\n",
        "canvas = Image.new(\"RGB\", (max_x, max_y), (255, 255, 255))\n",
        "\n",
        "for x, y, img in patches:\n",
        "    canvas.paste(img, (x, y))\n",
        "\n",
        "out_path = f\"reconstructed_{reso}.png\"\n",
        "canvas.save(out_path)\n",
        "print(f\"Reconstructed {reso} saved at {out_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare to the 10X original image"
      ],
      "metadata": {
        "id": "lnB0hLK7y8V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "I20 = np.array(Image.open(\"reconstructed_20x.png\").convert(\"RGB\"))\n",
        "I10 = np.array(Image.open(\"original0005f7aaab2800f6170c399693a96917.png\").convert(\"RGB\"))\n",
        "\n",
        "H10, W10 = I10.shape[:2]\n",
        "I20_to_10 = cv2.resize(I20, (W10, H10), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "mask_small = np.ones((H10, W10), dtype=np.uint8)\n",
        "\n",
        "mask_big = np.ones((I20_to_10.shape[0], I20_to_10.shape[1]), dtype=np.uint8)\n",
        "\n",
        "region_diff = cv2.subtract(mask_big, mask_small)\n",
        "cv2.imwrite(\"region_diff.png\", region_diff*255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6augGjD1jPz",
        "outputId": "74256e48-0270-4991-dbd3-5d92d2ead7f1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 如果最高层数宽度 除以 缩放倍数 （2） 整除后会四舍五入，所以会有宽的不同"
      ],
      "metadata": {
        "id": "oOerERdc4JQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_rgb(path):\n",
        "    return np.array(Image.open(path).convert(\"RGB\"))\n",
        "\n",
        "def compare_with_overlap(pathA, pathB, tol=0, out_prefix=\"cmp\"):\n",
        "    \"\"\"\n",
        "    从左上角对齐两张图，比较公共重叠区域像素是否相同，并高亮非重叠区域。\n",
        "    tol: 容差(0=严格逐像素；5~10 可忽略小插值/量化误差)\n",
        "    out_prefix: 输出文件名前缀\n",
        "    \"\"\"\n",
        "    A = read_rgb(pathA)\n",
        "    B = read_rgb(pathB)\n",
        "    H1, W1 = A.shape[:2]\n",
        "    H2, W2 = B.shape[:2]\n",
        "\n",
        "    h = min(H1, H2)\n",
        "    w = min(W1, W2)\n",
        "\n",
        "    A_ov = A[:h, :w]\n",
        "    B_ov = B[:h, :w]\n",
        "\n",
        "    if tol <= 0:\n",
        "        equal_mask = np.all(A_ov == B_ov, axis=-1)\n",
        "    else:\n",
        "        diff = np.abs(A_ov.astype(np.int16) - B_ov.astype(np.int16))\n",
        "        equal_mask = np.all(diff <= tol, axis=-1)\n",
        "\n",
        "    n_total = h * w\n",
        "    n_equal = int(equal_mask.sum())\n",
        "    n_diff  = n_total - n_equal\n",
        "    diff_ratio = n_diff / n_total if n_total else 0.0\n",
        "\n",
        "    ov_vis = A_ov.copy()\n",
        "    ov_vis[~equal_mask] = [255, 0, 0]\n",
        "    ov_blend = cv2.addWeighted(A_ov, 0.6, ov_vis, 0.4, 0)\n",
        "    cv2.imwrite(f\"{out_prefix}_overlap_diff.png\", ov_blend)\n",
        "\n",
        "    Hc, Wc = max(H1, H2), max(W1, W2)\n",
        "    canvasA = np.zeros((Hc, Wc, 3), dtype=np.uint8)\n",
        "    canvasB = np.zeros((Hc, Wc, 3), dtype=np.uint8)\n",
        "    canvasA[:H1, :W1] = A\n",
        "    canvasB[:H2, :W2] = B\n",
        "\n",
        "    coverA = np.zeros((Hc, Wc), dtype=np.uint8); coverA[:H1, :W1] = 1\n",
        "    coverB = np.zeros((Hc, Wc), dtype=np.uint8); coverB[:H2, :W2] = 1\n",
        "    onlyA = (coverA == 1) & (coverB == 0)\n",
        "    onlyB = (coverB == 1) & (coverA == 0)\n",
        "\n",
        "    vis_cover = np.zeros((Hc, Wc, 3), dtype=np.uint8)\n",
        "    vis_cover[onlyA] = [255, 0, 0]\n",
        "    vis_cover[onlyB] = [0, 0, 255]\n",
        "    cv2.imwrite(f\"{out_prefix}_non_overlap_map.png\", vis_cover)\n",
        "\n",
        "\n",
        "    stats = {\n",
        "        \"A_shape\": (H1, W1),\n",
        "        \"B_shape\": (H2, W2),\n",
        "        \"overlap_shape\": (h, w),\n",
        "        \"overlap_equal_pixels\": n_equal,\n",
        "        \"overlap_diff_pixels\": n_diff,\n",
        "        \"overlap_diff_ratio\": diff_ratio,   # 重叠区中不同像素占比\n",
        "        \"all_equal_in_overlap\": (n_diff == 0),\n",
        "    }\n",
        "\n",
        "    # 5) 方便肉眼复核：导出重叠区差异和覆盖差异的叠加图\n",
        "    # 把覆盖差异叠到较大的画布上显示\n",
        "    base = canvasA.copy()\n",
        "    ov_alpha = 0.5\n",
        "    cover_overlay = cv2.addWeighted(base, 1-ov_alpha, vis_cover, ov_alpha, 0)\n",
        "    cv2.imwrite(f\"{out_prefix}_non_overlap_overlay.png\", cover_overlay)\n",
        "\n",
        "    return stats\n",
        "\n",
        "# 用法：\n",
        "stats = compare_with_overlap(\"reconstructed_20x.png\", \"original0005f7aaab2800f6170c399693a96917.png\", tol=5, out_prefix=\"cmp\")\n",
        "print(stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0KmnpWc2rtf",
        "outputId": "237f9423-3af6-4fb4-f42a-eaec1063637d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A_shape': (1840, 1536), 'B_shape': (1840, 1728), 'overlap_shape': (1840, 1536), 'overlap_equal_pixels': 2826240, 'overlap_diff_pixels': 0, 'overlap_diff_ratio': 0.0, 'all_equal_in_overlap': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kjGGnAMu3YyG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}