{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlWmfy8s65bN"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28q1CI555p9f"
      },
      "source": [
        "### Connect to Drive and Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "MYfLehyB4TCc",
        "outputId": "ffa4712f-bd7c-4562-f740-09c501c9350a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e734d5fb-5aa4-4241-bc41-cc11f26cd593\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e734d5fb-5aa4-4241-bc41-cc11f26cd593\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"mackenziecheng\",\"key\":\"f6a65b977af5878d731672be3d779496\"}'}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaWgHajG4USV"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Kg2r014ZbF",
        "outputId": "16c200e8-7814-413d-c5e3-7281f5700c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyrubtob7Utg"
      },
      "source": [
        "### Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTeEvG6B7Eqr",
        "outputId": "57b566ee-f4f5-4ab5-c723-4f6f4fc90d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.12/dist-packages (1.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from openslide-python) (11.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.12/dist-packages (2025.8.28)\n",
            "Requirement already satisfied: zarr in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.12/dist-packages (2025.8.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tifffile) (2.0.2)\n",
            "Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.12/dist-packages (from zarr) (0.8.1.post1)\n",
            "Requirement already satisfied: numcodecs>=0.14 in /usr/local/lib/python3.12/dist-packages (from numcodecs[crc32c]>=0.14->zarr) (0.16.2)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.12/dist-packages (from zarr) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9 in /usr/local/lib/python3.12/dist-packages (from zarr) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr) (6.0.2)\n",
            "Requirement already satisfied: crc32c>=2.7 in /usr/local/lib/python3.12/dist-packages (from numcodecs[crc32c]>=0.14->zarr) (2.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# # Core WSI handling\n",
        "!pip install openslide-python\n",
        "\n",
        "# # Image processing\n",
        "!pip install opencv-python Pillow\n",
        "\n",
        "!pip install tifffile zarr imagecodecs opencv-python pillow pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "XvnHQjwE7iBF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "from glob import glob\n",
        "\n",
        "import tifffile as tiff, zarr\n",
        "import numpy as np\n",
        "import cv2, pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch, torchvision as tv\n",
        "import h5py\n",
        "\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QqOQ8kaG4oB"
      },
      "source": [
        "## Edge Detection - Contour function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TryZzyAXBkLW"
      },
      "outputs": [],
      "source": [
        "def _to_uint8(img):\n",
        "    if img.dtype == np.uint8: return img\n",
        "    x = img.astype(np.float32); mn, mx = float(x.min()), float(x.max())\n",
        "    if mx <= mn: return np.zeros_like(x, dtype=np.uint8)\n",
        "    return ((x - mn) / (mx - mn) * 255.0).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 通过饱和度分离组织和背景（饱和度高和白色）\n",
        "# 去掉噪点，让组织区域更连贯\n",
        "# 找到轮廓线 cv2.findContours\n",
        "def build_contour_mask_1024(\n",
        "    lowres_rgb, # 低分辨率彩色图\n",
        "    mthresh: int = 41,        # 去噪点\n",
        "    sthresh: int = 12,        # 分离前景背景\n",
        "    close: int = 2,           # morphology closing kernel\n",
        "    min_area_fore: int = 12,  # min area (low-res px) 低分辩像素个数\n",
        "    min_area_hole: int = 8,  # min hole area (low-res px)\n",
        "    max_n_holes: int = 8,     # cap holes per region 最多保留孔洞数量\n",
        "):\n",
        "\n",
        "\n",
        "    img = _to_uint8(lowres_rgb)\n",
        "    # 组织区域更有颜色，和白色对比强\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV); sat = hsv[..., 1]\n",
        "    sat = cv2.medianBlur(sat, int(max(1, mthresh) | 1))\n",
        "    _, bin_s = cv2.threshold(sat, int(sthresh), 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # 填补小缝隙\n",
        "    if close > 0:\n",
        "        kernel = np.ones((int(close), int(close)), np.uint8)\n",
        "        bin_s = cv2.morphologyEx(bin_s, cv2.MORPH_CLOSE, kernel)\n",
        "    contours, hier = cv2.findContours(bin_s, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    if hier is None or len(contours) == 0:\n",
        "        return (bin_s > 0)\n",
        "    hier = hier[0]  # [Next, Prev, First_Child, Parent]\n",
        "    fore_ids = [i for i,h in enumerate(hier) if h[3] == -1]\n",
        "    kept_fore, holes_per_fore = [], []\n",
        "    for fid in fore_ids:\n",
        "        a = cv2.contourArea(contours[fid])\n",
        "        if a <= 0: continue\n",
        "        # collect children (holes)\n",
        "        holes = []\n",
        "        child = hier[fid][2]\n",
        "        while child != -1:\n",
        "            holes.append(child)\n",
        "            child = hier[child][0]\n",
        "        hole_areas = [cv2.contourArea(contours[h]) for h in holes]\n",
        "        real_a = a - (np.sum(hole_areas) if hole_areas else 0.0)\n",
        "        if real_a >= float(min_area_fore):\n",
        "            kept_fore.append(fid)\n",
        "            holes_kept = [h for h in holes if cv2.contourArea(contours[h]) > float(min_area_hole)]\n",
        "            holes_kept = sorted(holes_kept, key=lambda h: cv2.contourArea(contours[h]), reverse=True)[:max_n_holes]\n",
        "            holes_per_fore.append(holes_kept)\n",
        "    H, W = bin_s.shape\n",
        "    mask = np.zeros((H, W), dtype=np.uint8)\n",
        "    if kept_fore:\n",
        "        cv2.drawContours(mask, [contours[i] for i in kept_fore], -1, 255, thickness=cv2.FILLED)\n",
        "    for holes in holes_per_fore:\n",
        "        if holes:\n",
        "            cv2.drawContours(mask, [contours[i] for i in holes], -1, 0, thickness=cv2.FILLED)\n",
        "    return (mask > 0)\n",
        "\n",
        "\n",
        "# 是否留下patch\n",
        "# 组织是否较多？是否有边缘？\n",
        "def patch_keep(mask_bool, x_m, y_m, w_m, h_m, min_tissue = 0.20, min_edge = 0.05):\n",
        "    H, W = mask_bool.shape[:2]\n",
        "    x2, y2 = min(W, x_m + w_m), min(H, y_m + h_m)\n",
        "    if x_m >= x2 or y_m >= y2: return False, {'cov':0.0,'edge':0.0}\n",
        "    win = mask_bool[y_m:y2, x_m:x2]\n",
        "    if win.size == 0: return False, {'cov':0.0,'edge':0.0}\n",
        "    cov = float(win.mean())\n",
        "    if cov == 0.0:\n",
        "        edge_ratio = 0.0\n",
        "    else:\n",
        "        eroded = cv2.erode(win.astype(np.uint8), np.ones((3,3), np.uint8), 1).astype(bool)\n",
        "        border = win ^ eroded\n",
        "        edge_ratio = float(border.mean())\n",
        "    keep = (cov >= min_tissue) or (edge_ratio >= min_edge)\n",
        "    return keep, {'cov': cov, 'edge': edge_ratio}\n",
        "\n",
        "# 打分数\n",
        "# score = 0.6 * 组织覆盖率 + 0.4 * edge\n",
        "def rank_key(stats: dict, alpha: float = 0.6):\n",
        "    return alpha*float(stats.get('cov',0.0)) + (1.0-alpha)*float(stats.get('edge',0.0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuKcliGy5wQE"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "tMtz_p-A4axj"
      },
      "outputs": [],
      "source": [
        "drive_path = '/content/drive/MyDrive/PANDA_OneImage'\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "image_id = '0005f7aaab2800f6170c399693a96917'\n",
        "image_filename = f'train_images/{image_id}.tiff'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ2hyLD94mT_",
        "outputId": "8e8837a0-eadb-41b1-9228-8ad5e3b22d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "0005f7aaab2800f6170c399693a96917.tiff: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c prostate-cancer-grade-assessment -f train.csv -p '{drive_path}'\n",
        "!kaggle competitions download -c prostate-cancer-grade-assessment -f '{image_filename}' -p '{drive_path}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McnWP4JsxYxl",
        "outputId": "e98b7bde-ed95-46bc-e41a-56553e45b818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['train.csv', '0005f7aaab2800f6170c399693a96917.tiff', 'patches_20x', 'extracted']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(drive_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6PtuKSjpUN0",
        "outputId": "37add2ae-9372-40a3-b51d-5e8564f47268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Exists: True\n",
            "Size (MB): 15.38\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, pathlib\n",
        "drive_path = '/content/drive/MyDrive/PANDA_OneImage'\n",
        "image_id = '0005f7aaab2800f6170c399693a96917'\n",
        "image_filename = f'{image_id}.tiff'\n",
        "tiff_path = os.path.join(drive_path, image_filename)\n",
        "\n",
        "print(\"Exists:\", os.path.exists(tiff_path))\n",
        "print(\"Size (MB):\", round(os.path.getsize(tiff_path)/1024/1024, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYMrpHq7zdxa"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY3rYfKO8p1t"
      },
      "source": [
        "### Import and unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKY4OoOz8Hok"
      },
      "source": [
        "*   Many documents implment with OpenSlide, but this Kaggle one does not work as it's a zip --> tifffile and zarr\n",
        "\n",
        "\n",
        "*   forgetground threshold: reject patches if less than % of pixels are tissues\n",
        "\n",
        "*   min std: reject patches with low variations (blank)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TuofGemusdP1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# with tiff.TiffFile(f'{drive_path}/0005f7aaab2800f6170c399693a96917.tiff') as tf:\n",
        "#   print(len(tf.series[0].levels))   # number of pyramid levels\n",
        "#   for lvl in tf.series[0].levels:\n",
        "#     print(lvl.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaVREMyN1bnY"
      },
      "outputs": [],
      "source": [
        "ZIP_OR_TIFF_PATH = f'/content/drive/MyDrive/PANDA_OneImage/{image_id}.tiff'\n",
        "\n",
        "# output path\n",
        "EXTRACT_DIR = '/content/drive/MyDrive/PANDA_OneImage/extracted'     # where we unzip and get the real tiff\n",
        "OUT_DIR     = '/content/drive/MyDrive/PANDA_OneImage/patches_20x'   # where we save patches/CSV, all outputs\n",
        "\n",
        "\n",
        "\n",
        "# resolution flag\n",
        "# reso = '20x'\n",
        "reso = '10x'\n",
        "\n",
        "Path(EXTRACT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bsiMhCLq14kF"
      },
      "outputs": [],
      "source": [
        "# unzip the file and return the real tiff\n",
        "def get_real_tiff(path: str):\n",
        "    # if file starts with 'PK', it's a ZIP\n",
        "    with open(path, 'rb') as f:\n",
        "        sig = f.read(2)\n",
        "    if sig == b'PK':\n",
        "        with zipfile.ZipFile(path) as z:\n",
        "            print('Archive contents:', z.namelist())\n",
        "            z.extractall(EXTRACT_DIR)\n",
        "        tiffs = sorted(glob(os.path.join(EXTRACT_DIR, '**', '*.tif*'), recursive=True))\n",
        "        if not tiffs:\n",
        "            raise FileNotFoundError('No .tif/.tiff found after extraction.')\n",
        "        return tiffs[0]\n",
        "    return path\n",
        "\n",
        "\n",
        "# zarr: n-dimensional array, like NumPy, but load what you need when you need\n",
        "# WSIs giant -> zarr\n",
        "# get the actual array of the pixel data\n",
        "def _to_zarr_array(znode):\n",
        "    obj = zarr.open(znode, mode='r')\n",
        "    # if a single array\n",
        "    if isinstance(obj, zarr.Array):\n",
        "        return obj\n",
        "    # if a group with multi arrays\n",
        "    if isinstance(obj, zarr.Group):\n",
        "        keys = list(obj.array_keys())\n",
        "        if not keys:\n",
        "            raise ValueError('Zarr Group has no arrays.')\n",
        "        return obj[keys[0]]\n",
        "    raise TypeError(f'Unexpected zarr node type: {type(obj)}')\n",
        "\n",
        "\n",
        "# open the first image in tiff\n",
        "# collect all levels （pyramid) , 40x --> 20x --> 10x....\n",
        "def open_pyramid_as_zarr(tf: tiff.TiffFile):\n",
        "\n",
        "    s0 = tf.series[0]\n",
        "    arr0 = _to_zarr_array(s0.aszarr())        # level 0 (highest resolution)\n",
        "    levels = [arr0] + [_to_zarr_array(l.aszarr()) for l in s0.levels]\n",
        "    # compute downsample factors related to level 0\n",
        "    # eg: L0 wid = 1000, L1 wid = 500, 1000 / 500 = 2\n",
        "    downs = [1.0] + [arr0.shape[-2] / lvl.shape[-2] for lvl in levels[1:]]\n",
        "    return levels, downs\n",
        "\n",
        "# pick the one closest to my target, 20X here\n",
        "def pick_level_for_target(downs, target_down=1.0):\n",
        "    return int(np.argmin([abs(d - target_down) for d in downs]))\n",
        "\n",
        "# standardize all to RGB unit8 format (H, W, 3)\n",
        "def ensure_hwc(tile: np.ndarray):\n",
        "    t = tile\n",
        "    if t.ndim == 2: # grayscale\n",
        "        t = np.stack([t]*3, axis=-1)\n",
        "    elif t.ndim == 3 and t.shape[0] in (3,4) and t.shape[-1] not in (3,4): # (C, H, W)\n",
        "        t = np.moveaxis(t, 0, -1)  # (C,H,W) -> (H,W,C)\n",
        "    if t.shape[-1] > 3: # RGBA with alpha\n",
        "        t = t[..., :3]            # drop alpha\n",
        "    if t.dtype != np.uint8: # other format\n",
        "        # best-effort clamp/convert (many WSIs are already uint8)\n",
        "        t = np.clip(t, 0, 255).astype(np.uint8)\n",
        "    return t\n",
        "\n",
        "def save_png(arr: np.ndarray, path: Path):\n",
        "    Image.fromarray(arr).save(path, format='PNG', compress_level=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcf5CDNR16Ns",
        "outputId": "3d2ae686-c3a5-4300-fa31-fb02168e32f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive contents: ['0005f7aaab2800f6170c399693a96917.tiff']\n",
            "Using TIFF: /content/drive/MyDrive/PANDA_OneImage/extracted/0005f7aaab2800f6170c399693a96917.tiff\n"
          ]
        }
      ],
      "source": [
        "REAL_TIFF_PATH = get_real_tiff(ZIP_OR_TIFF_PATH)\n",
        "print('Using TIFF:', REAL_TIFF_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "xm8h6hrxqB76"
      },
      "outputs": [],
      "source": [
        "with tiff.TiffFile(REAL_TIFF_PATH) as tf:\n",
        "    series = tf.series[0]\n",
        "    low = series.levels[-1].asarray()\n",
        "    img = Image.fromarray(low)\n",
        "\n",
        "img.save(f\"original{image_id}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5xjN856tTWW",
        "outputId": "985fb282-ae4f-4264-d6bd-b23fce905550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "(29440, 27648, 3)\n",
            "(7360, 6912, 3)\n",
            "(1840, 1728, 3)\n"
          ]
        }
      ],
      "source": [
        "import tifffile as tiff\n",
        "with tiff.TiffFile('/content/drive/MyDrive/PANDA_OneImage/extracted/0005f7aaab2800f6170c399693a96917.tiff') as tf:\n",
        "    print(len(tf.series[0].levels))   # number of pyramid levels\n",
        "    for lvl in tf.series[0].levels:\n",
        "        print(lvl.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if reso == '20x':\n",
        "  # base level: 20X\n",
        "  hi_level = 0\n",
        "  PATCH, STRIDE = 1024, 512\n",
        "  TARGET_DOWN = 1.0\n",
        "\n",
        "else:\n",
        "  # 10x level\n",
        "  hi_level = 1\n",
        "  PATCH, STRIDE = 512, 256\n",
        "  TARGET_DOWN = 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEGwdPnkt9Nw",
        "outputId": "a02d0d39-3ae2-4a7e-8bc4-fb6aa5d0605c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pyramid downsample factors vs level-0: ['1.00×', '1.00×', '1.00×', '4.00×']\n",
            "Chosen level: 0  (downsample 1.00×),  shape≈(7360, 6912, …)\n"
          ]
        }
      ],
      "source": [
        "with tiff.TiffFile(REAL_TIFF_PATH) as tf:\n",
        "    levels, downs = open_pyramid_as_zarr(tf)\n",
        "\n",
        "print('Pyramid downsample factors vs level-0:', [f'{d:.2f}×' for d in downs])\n",
        "\n",
        "L = pick_level_for_target(downs, TARGET_DOWN)\n",
        "arrL = levels[L]\n",
        "\n",
        "# extract H and W\n",
        "H, W = arrL.shape[-3], arrL.shape[-2]\n",
        "print(f'Chosen level: {L}  (downsample {downs[L]:.2f}×),  shape≈({H}, {W}, …)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fbBewaLG83n"
      },
      "source": [
        "## Run Contour part to get the non-black part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehxgpwYqg-TJ",
        "outputId": "5b343043-f8a1-4a83-db30-6c7afc5e9e72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2673612727.py:57: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  Image.fromarray(_to_uint8(tile), 'RGB').save(os.path.join(out_dir, f'p_x{x}_y{y}_s{score:.3f}.png'))\n"
          ]
        }
      ],
      "source": [
        "# choose the lowest reso to build the mask\n",
        "low_level = len(levels) - 1\n",
        "arr_low = levels[low_level]\n",
        "lowres_rgb = np.asarray(arr_low)  # (H_low, W_low, 3) uint8\n",
        "H_low, W_low = lowres_rgb.shape[:2]\n",
        "\n",
        "\n",
        "\n",
        "arr0 = levels[hi_level]\n",
        "H0, W0 = arr0.shape[0], arr0.shape[1]\n",
        "\n",
        "# Map factor: pixels at hi_level → pixels at low_level\n",
        "# If your 'downs' is defined as (down from level 0), then:\n",
        "#   scale_hi_to_low = downs[hi_level] / downs[low_level]\n",
        "# For hi_level=0 this simplifies to:\n",
        "scale_hi_to_low = downs[hi_level] / downs[low_level]\n",
        "\n",
        "# Build the contour mask at the low-res level\n",
        "contour_mask = build_contour_mask_1024(lowres_rgb)\n",
        "\n",
        "\n",
        "out_dir = f'patches_out_{reso}'; os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "kept = []\n",
        "for y in range(0, H0 - PATCH + 1, STRIDE):\n",
        "    for x in range(0, W0 - PATCH + 1, STRIDE):\n",
        "        # Map hi-res patch → low-res mask window\n",
        "        x_m = int(x * scale_hi_to_low)\n",
        "        y_m = int(y * scale_hi_to_low)\n",
        "        w_m = max(1, int(PATCH * scale_hi_to_low))\n",
        "        h_m = max(1, int(PATCH * scale_hi_to_low))\n",
        "\n",
        "        keep, stats = patch_keep(contour_mask, x_m, y_m, w_m, h_m, min_tissue=0.20, min_edge=0.05)\n",
        "        if not keep:\n",
        "            continue\n",
        "\n",
        "        score = rank_key(stats, alpha=0.6)\n",
        "        kept.append((score, x, y))\n",
        "\n",
        "        # Read hi-res tile directly from zarr and save\n",
        "        tile = np.asarray(arr0[y:y+PATCH, x:x+PATCH, :])\n",
        "        if tile.shape[:2] != (PATCH, PATCH):\n",
        "            continue\n",
        "        Image.fromarray(_to_uint8(tile), 'RGB').save(os.path.join(out_dir, f'p_x{x}_y{y}_s{score:.3f}.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmwRFC1cD-kV",
        "outputId": "6a2f5f31-4894-450b-e829-f697369e7119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reconstructed 10x saved at reconstructed_10x.png\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Folder where your patches are stored\n",
        "PATCH_DIR = f\"patches_out_{reso}\"\n",
        "\n",
        "# Regex to parse filenames like p_x1024_y1024_s0.187.png\n",
        "pattern = re.compile(r\"p_x(\\d+)_y(\\d+)_s[\\d.]+\\.png\")\n",
        "\n",
        "# Load all patches and record their coordinates\n",
        "patches = []\n",
        "max_x, max_y = 0, 0\n",
        "\n",
        "for fname in os.listdir(PATCH_DIR):\n",
        "    match = pattern.match(fname)\n",
        "    if not match:\n",
        "        continue\n",
        "    x, y = int(match.group(1)), int(match.group(2))\n",
        "    img = Image.open(os.path.join(PATCH_DIR, fname))\n",
        "    w, h = img.size\n",
        "    patches.append((x, y, img))\n",
        "\n",
        "    # Track max extent of the canvas\n",
        "    max_x = max(max_x, x + w)\n",
        "    max_y = max(max_y, y + h)\n",
        "\n",
        "# Create a blank canvas large enough to hold all patches\n",
        "canvas = Image.new(\"RGB\", (max_x, max_y), (255, 255, 255))\n",
        "\n",
        "# Paste each patch onto the canvas\n",
        "for x, y, img in patches:\n",
        "    canvas.paste(img, (x, y))\n",
        "\n",
        "# Save the reconstructed image\n",
        "out_path = f\"reconstructed_{reso}.png\"\n",
        "canvas.save(out_path)\n",
        "print(f\"Reconstructed {reso} saved at {out_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNyTi9MUicqh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
